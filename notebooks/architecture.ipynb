{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture\n",
    "\n",
    "<img src='diags/nn_1.dio.drawio.svg'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Symbols & Naming Conventions\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "    n &= \\text{number of nodes}\\\\\n",
    "    l &= \\text{layer number}\\\\\n",
    "    w,W &= \\text{weights matrix}\\\\\n",
    "    b &= \\text{bias matrix}\\\\\n",
    "    z,Z &= \\text{hypthesis result (result before applying activation function)}\\\\\n",
    "    g(z) &= \\text{activation function}\\\\\n",
    "    a,A &= \\text{activation matrix (result after applying activation function)}\\\\\n",
    "    x,X &= \\text{input to network}\\\\\n",
    "    \\hat{y} &= \\text{output of network}\\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "values for forward propogation\n",
    "\\begin{align}\n",
    "    \\huge{n^{[l]}} &= \\text{number of nodes in the layer}\\\\\n",
    "    \\huge{z^{[l]}} &= \\text{hypothesis result of the layer}\\\\\n",
    "    \\huge{w^{[l]}} &= \\text{weights results of the layer}\\\\\n",
    "    \\huge{b^{[l]}} &= \\text{bias results of the layer}\\\\\n",
    "    \\huge{a^{[l]}} &= \\text{activation results of the layer}\\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "derivatives for backward propogation\n",
    "\\begin{align}\n",
    "    \\huge{dw^{[l]}} &= \\frac{\\partial L}{\\partial w} \\rightarrow \\text{loss derivative based on weights}\\\\\n",
    "    \\huge{db^{[l]}} &= \\frac{\\partial L}{\\partial b} \\rightarrow \\text{ loss derivative based on biases}\\\\\n",
    "    \\huge{dz^{[l]}} &= \\frac{\\partial L}{\\partial z} \\rightarrow \\text{ loss derivative based on hypothesis result}\\\\\n",
    "    \\huge{da^{[l]}} &= \\frac{\\partial L}{\\partial a} \\rightarrow \\text{ loss derivative based on activation result}\\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flow\n",
    "\n",
    "<img src='diags/nn_flow.drawio.svg'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Shapes \n",
    "\n",
    "\n",
    "\\begin{array}{ | c | c | c | }\n",
    "    \\hline\n",
    "    W^{[l]} & ( n^{[l]} , n^{[l-1]} ) & dW^{[l]} \\\\\n",
    "    \\hline\n",
    "    b^{[l]} & ( 1 , n^{[l]}  ) & db^{[l]} \\\\\n",
    "    \\hline\n",
    "    Z^{[l]} & ( n^{[l]} , n^{[l-1]} ) & dZ^{[l]} \\\\\n",
    "    \\hline\n",
    "    A^{[l]} & ( n^{[l]} , n^{[l-1]} ) & dA^{[l]} \\\\\n",
    "    \\hline\n",
    "\\end{array} \n",
    "where\\\n",
    "l = layer number >= 1\\\n",
    "$A^{[0]}$ = X"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python383jvsc74a57bd01da5964c5502736b4e0a0c4398fb3b913682175f516e99bd48540f11726a612c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
