{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Dense Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we actually initialize a layer for a New Neural Network?\n",
    "\n",
    "* initialization of weights with small random values\n",
    "\n",
    "    * why? because according to Andrew Ng's explanation if all the weights/params are\n",
    "    initialized by zero or same value then all the hidden units will be symmetric with identical nodes.\n",
    "    \n",
    "    * With identical nodes there will be no learning/ decision making. because all the decisions\n",
    "    shares same value.\n",
    "    \n",
    "    * If all the nodes will have zero values(weights are zero , multiplication with weights will also be zero) and propogation result wont be a conclusive one(dead network).\n",
    "\n",
    "* initialization of bias can be zero. \n",
    "\n",
    "    * as randomness is already introduced by weights.\n",
    "    But for smaller Neural Network it is advised to not to initialize with zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "X &= \\begin{bmatrix}\n",
    "x_1^{(1)} & x_1^{(2)} & \\dots & x_1^{(m)}\\\\\n",
    "x_2^{(1)} & x_2^{(2)} & \\dots & x_2^{(m)}\\\\\n",
    "& & \\vdots \\\\\n",
    "x_n^{(1)} & x_n^{(2)} & \\dots & x_n^{(m)}\\\\\n",
    "\\end{bmatrix}_{n \\times m}\\\\\n",
    "W &= \\begin{bmatrix}\n",
    "w_1^{(1)} & w_1^{(2)} & \\dots & w_1^{(m)}\\\\\n",
    "w_2^{(1)} & w_2^{(2)} & \\dots & w_2^{(m)}\\\\\n",
    "& & \\vdots \\\\\n",
    "w_n^{(1)} & w_n^{(2)} & \\dots & w_n^{(m)}\\\\\n",
    "\\end{bmatrix}_{n \\times m}\\\\\n",
    "b &= \\begin{bmatrix}\n",
    "b_1 & b_2 & \\dots & b_n\n",
    "\\end{bmatrix}_{1 \\times n}\\\\\n",
    "Z &= X W^T + b\\\\\n",
    "\\\\\n",
    "&=\\begin{bmatrix}\n",
    "x_1^{(1)} & x_1^{(2)} & \\dots & x_1^{(m)}\\\\\n",
    "x_2^{(1)} & x_2^{(2)} & \\dots & x_2^{(m)}\\\\\n",
    "& & \\vdots \\\\\n",
    "x_n^{(1)} & x_n^{(2)} & \\dots & x_n^{(m)}\\\\\n",
    "\\end{bmatrix}_{n \\times m}\n",
    "\\begin{bmatrix}\n",
    "w_1^{(1)} & w_2^{(1)} & \\dots & w_n^{(1)}\\\\\n",
    "w_1^{(2)} & w_2^{(2)} & \\dots & w_n^{(2)}\\\\\n",
    "& & \\vdots \\\\\n",
    "w_1^{(m)} & w_2^{(m)} & \\dots & w_n^{(m)}\\\\\n",
    "\\end{bmatrix}_{m \\times n}+\n",
    "\\begin{bmatrix}\n",
    "b_1 & b_2 & \\dots & b_n\n",
    "\\end{bmatrix}_{1 \\times n}\\\\\n",
    "\\\\\n",
    "&= \\begin{bmatrix}\n",
    "x_1^{(1)}w_1^{(1)}+ x_1^{(2)}w_1^{(2)} +\\dots+x_1^{(m)}w_1^{(m)} & \\dots & x_1^{(1)}w_n^{(1)}+ x_1^{(2)}w_n^{(2)} +\\dots+x_1^{(m)}w_n^{(m)} \\\\\n",
    "x_2^{(1)}w_1^{(1)}+ x_2^{(2)}w_1^{(2)} +\\dots+x_2^{(m)}w_1^{(m)} & \\dots & x_2^{(1)}w_n^{(1)}+ x_2^{(2)}w_n^{(2)} +\\dots+x_2^{(m)}w_n^{(m)} \\\\\n",
    "& \\vdots \\\\\n",
    "x_n^{(1)}w_1^{(1)}+ x_n^{(2)}w_1^{(2)} +\\dots+x_n^{(m)}w_1^{(m)} & \\dots & x_n^{(1)}w_n^{(1)}+ x_n^{(2)}w_n^{(2)} +\\dots+x_n^{(m)}w_n^{(m)}\n",
    "\\end{bmatrix}_{n \\times n} +\n",
    "\\begin{bmatrix}\n",
    "b_1 & b_2 & \\dots & b_n\\\\\n",
    "b_1 & b_2 & \\dots & b_n\\\\\n",
    "& & \\vdots\\\\\n",
    "b_1 & b_2 & \\dots & b_n\\\\\n",
    "\\end{bmatrix}_{n \\times n \\text{ broadcasting}}\\\\\n",
    "\\\\\n",
    "&= \\begin{bmatrix}\n",
    "x_1^{(1)}w_1^{(1)}+ x_1^{(2)}w_1^{(2)} +\\dots+x_1^{(m)}w_1^{(m)} + b_1 & \\dots & x_1^{(1)}w_n^{(1)}+ x_1^{(2)}w_n^{(2)} +\\dots+x_1^{(m)}w_n^{(m)}+ b_n \\\\\n",
    "x_2^{(1)}w_1^{(1)}+ x_2^{(2)}w_1^{(2)} +\\dots+x_2^{(m)}w_1^{(m)} + b_1 & \\dots & x_2^{(1)}w_n^{(1)}+ x_2^{(2)}w_n^{(2)} +\\dots+x_2^{(m)}w_n^{(m)}+ b_n \\\\\n",
    "& \\vdots \\\\\n",
    "x_n^{(1)}w_1^{(1)}+ x_n^{(2)}w_1^{(2)} +\\dots+x_n^{(m)}w_1^{(m)} + b_1 & \\dots & x_n^{(1)}w_n^{(1)}+ x_n^{(2)}w_n^{(2)} +\\dots+x_n^{(m)}w_n^{(m)} + b_n\n",
    "\\end{bmatrix}_{n \\times n}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward\n",
    "\n",
    "\\begin{align*}\n",
    "Z^{[1]} &= A^{[0]} W^{[1]T} + b^{[1]}\\\\\n",
    "A^{[1]} &= g^{[1]}(Z^{[1]})\\\\\n",
    "\\\\\n",
    "Z^{[2]} &= A^{[1]} W^{[2]T} + b^{[2]}\\\\\n",
    "A^{[2]} &= g^{[2]}(Z^{[2]})\\\\\n",
    "\\end{align*}\n",
    "\n",
    "`Generalized`\n",
    "\\begin{align*}\n",
    "Z^{[l]} &= A^{[l-1]} W^{[l]T} + b^{[l]}\\\\\n",
    "A^{[l]} &= g^{[l]}(Z^{[l]})\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC,abstractmethod\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets take two layers\n",
    "\n",
    "* lets take layer 1 as input layer. This means input is x or $a^{[0]}$\n",
    "    * lets take 3 columns = number of nodes = $n^{[0]} = 3$\n",
    "    * and take 10 samples = m = 10\n",
    "    * shape of $a^{[0]} = (n^{[0]},m)$ \n",
    "                        (3, 10)\n",
    "    * shape of $w^{[1]} = (n^{[0]},m) = dw^{[1]}$ \n",
    "                    (3, 10)\n",
    "    * shape of $b^{[1]} = (1, n^{[0]}) = db^{[1]}$ \n",
    "                    (1, 3)\n",
    "    * shape of $z^{[1]} = (n^{[0]},m) (m, n^{[0]}) + (1, n^{[0]}) = (n^{[0]}, n^{[0]}) = dz^{[1]}$\n",
    "                     (3, 10) (10, 3)+ (1, 3) = (3, 3)\n",
    "    * shape of $z^{[1]}$ = shape of $a^{[1]} = (n^{[0]}, n^{[0]})$\n",
    "                                    (3, 3)\n",
    "\n",
    "* lets take layer 2 the next layer to that. The first one in hidden layer. Input to this layer is $a^{[1]}$\n",
    "    * lets take number of nodes in the layer = 5 = $n^{[1]} = 5$\n",
    "    * shape of $w^{[2]} = (n^{[1]},n^{[0]}) = dw^{[2]}$ \n",
    "                        (5 ,3)\n",
    "    * shape of $b^{[2]} = (1, n^{[1]}) = db^{[2]}$ \n",
    "                    (1, 5)\n",
    "    * shape of $z^{[2]} = (n^{[0]}, n^{[0]}) ( n^{[0]}, n^{[1]}) + (1, n^{[1]}) = (n^{[0]},n^{[1]}) = dz^{[2]}$\n",
    "                    (3, 3) (3, 5) + (1, 5) = (3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n0 = 3 \n",
    "n1 = 5\n",
    "m = 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 10) (3, 10) + (1, 3)\n"
     ]
    }
   ],
   "source": [
    "a0 = np.random.random((n0, m))\n",
    "w1 = np.random.random((n0, m))\n",
    "b1 = np.random.random((1, n0))\n",
    "print(w1.shape, a0.shape,'+', b1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z1 = (a0 @ w1.T) + b1\n",
    "z1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1 = 1/(1 + np.exp(-z1))\n",
    "\n",
    "a1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 3) (3, 3) + (1, 5)\n"
     ]
    }
   ],
   "source": [
    "w2 = np.random.random((n1, n0))\n",
    "b2 = np.random.random((1, n1))\n",
    "print(w2.shape, a1.shape,'+', b2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z2 = (a1 @ w2.T) + b2\n",
    "z2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2 = 1/(1 + np.exp(-z2))\n",
    "a2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backward\n",
    "\n",
    "\\begin{align*}\n",
    "& \\text{param for this layer  (this function starts working from here)}\\\\\n",
    "dW &= dZ' .A^T\\\\\n",
    "dB &= \\sum(dZ')\\\\\n",
    "\\\\\n",
    "& \\text{input for next layer (in backward propogation)}\\\\\n",
    "dZ &= dZ' .W^T \n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dz2 = np.random.random((n0,n1))\n",
    "dz2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dw2 = dz2 @ a2.T\n",
    "dw2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db2 = dz2.sum(axis=0,keepdims=True)\n",
    "db2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dz1 = dz2 @ w2\n",
    "dz1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dw1 = dz1 @ a1.T\n",
    "dw1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db1 = dz1.sum(axis=0,keepdims=True)\n",
    "db1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00430696, 1.12665459, 1.27528356, 0.37028909, 1.83008842,\n",
       "        0.86290497, 1.23745471, 1.23044548, 0.83923269, 1.65279249],\n",
       "       [0.77372465, 0.99710549, 1.00752794, 0.2431575 , 1.27532378,\n",
       "        0.7486004 , 1.11498651, 0.84140139, 0.61524338, 1.5975826 ],\n",
       "       [1.57524514, 1.82300126, 2.04126706, 0.56541619, 2.87108659,\n",
       "        1.40560442, 2.03900305, 1.88715055, 1.31532754, 2.74793296]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dz1 @ w1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerDense:\n",
    "    \"\"\"Layer Module\n",
    "    \n",
    "    It is recommended that input data X is scaled(data scaling operations)\n",
    "    so that data is normalized but meaning of the data remains same.\n",
    "\n",
    "    Args:\n",
    "        n_inputs (int) : number of inputs \n",
    "        n_neurons (int) : number of neurons\n",
    "    \"\"\"\n",
    "    def __init__(self,n_inputs,n_neurons):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        self.w = 0.10 * np.random.randn(n_inputs,n_neurons) # multiply by 0.1 to make it small\n",
    "        self.b = np.zeros((1,n_neurons))\n",
    "\n",
    "    def forward(self, a):\n",
    "        \"\"\"forward propogation calculation\n",
    "        \"\"\"\n",
    "        self.a = a\n",
    "        self.z = np.dot(self.a,self.w)+self.b \n",
    "\n",
    "    def backward(self, dz):\n",
    "        \"\"\"backward pass\n",
    "        \"\"\"\n",
    "        # gradient on parameters \n",
    "        self.dw = dz @ self.a.T\n",
    "        self.db = dz.sum(axis=0,keepdims=True)\n",
    "        \n",
    "        # gradient on values / input to next layer in backpropogation\n",
    "        self.dz = dz @ self.w"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python383jvsc74a57bd01da5964c5502736b4e0a0c4398fb3b913682175f516e99bd48540f11726a612c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
